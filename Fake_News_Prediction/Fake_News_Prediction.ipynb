{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaIBmnXCknPl"
      },
      "source": [
        "Credit=Siddarthan\n",
        "https://www.youtube.com/watch?v=nacLBdyG6jE&t=2767s\n",
        "\n",
        "About the Dataset:\n",
        "\n",
        "I have made some changes\n",
        "\n",
        "\n",
        "1. id: unique id for a news article\n",
        "2. title: the title of a news article\n",
        "3. author: author of the news article\n",
        "4. text: the text of the article; could be incomplete\n",
        "5. label: a label that marks whether the news article is real or fake:\n",
        "           1: Fake news\n",
        "           0: real News\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "egPJk-Gsj1ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c fake-news"
      ],
      "metadata": {
        "id": "NPVKizj0j7qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/fake-news.zip'"
      ],
      "metadata": {
        "id": "dARSbfSKj-em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k399dHafvL5N"
      },
      "source": [
        "Importing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fetC5yqkPVe"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AC1YpmGwIDw"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxIOt3DowpUR"
      },
      "source": [
        "# printing the stopwords in English\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjeGd1CLw_6R"
      },
      "source": [
        "Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCGcpu_1wzLw"
      },
      "source": [
        "# loading the dataset to a pandas DataFrame\n",
        "news_dataset = pd.read_csv('/content/train.csv')\n",
        "test=pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRgmbYSbxV4-"
      },
      "source": [
        "news_dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjJ1eB6RxZaS"
      },
      "source": [
        "# print the first 5 rows of the dataframe\n",
        "news_dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYkDi4SwxlKi"
      },
      "source": [
        "# counting the number of missing values in the dataset\n",
        "news_dataset.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.isnull().sum()"
      ],
      "metadata": {
        "id": "bhg3kVpP0S1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc04lQrhx57m"
      },
      "source": [
        "# replacing the null values with empty string\n",
        "news_dataset = news_dataset.fillna('')\n",
        "test=test.fillna('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7TZgHszygxj"
      },
      "source": [
        "# merging the author name and news title\n",
        "news_dataset['content'] = news_dataset['author']+' '+news_dataset['title']\n",
        "test['content'] = test['author']+' '+test['title']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbF6GBBpzBey"
      },
      "source": [
        "print(news_dataset['content'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "-ocgBdWik1Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.drop(columns=['text','author','title'],inplace=True)"
      ],
      "metadata": {
        "id": "RbqTuhZLlFSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "2jBELr34lPW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset.drop(columns=['text','author','title'],inplace=True)"
      ],
      "metadata": {
        "id": "ekfINA_P0tyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_dataset.head()"
      ],
      "metadata": {
        "id": "9WT4huUJ0y1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfBtAvLtzEo6"
      },
      "source": [
        "# separating the data & label\n",
        "X = news_dataset.drop(columns='label', axis=1)\n",
        "Y = news_dataset['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NwFcpqcz37a"
      },
      "source": [
        "Stemming:\n",
        "\n",
        "Stemming is the process of reducing a word to its Root word\n",
        "\n",
        "example:\n",
        "actor, actress, acting --> act"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga_DaZxhzoWM"
      },
      "source": [
        "port_stem = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY-n0dCh0e-y"
      },
      "source": [
        "def stemming(content):\n",
        "    stemmed_content = re.sub('[^a-zA-Z]',' ',content)\n",
        "    stemmed_content = stemmed_content.lower()\n",
        "    stemmed_content = stemmed_content.split()\n",
        "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
        "    stemmed_content = ' '.join(stemmed_content)\n",
        "    return stemmed_content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBUIk4c94yTL"
      },
      "source": [
        "news_dataset['content'] = news_dataset['content'].apply(stemming)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmwK-zyO5Stg"
      },
      "source": [
        "print(news_dataset['content'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZIidnta5k5h"
      },
      "source": [
        "#separating the data and label\n",
        "X = news_dataset['content'].values\n",
        "Y = news_dataset['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = test['content'].values\n"
      ],
      "metadata": {
        "id": "6lW7qb7M1gfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nA_SBZX6BeH"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgkFGXkg6HS4"
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu2ZEBkL6QTm"
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMfepsQZ6TES"
      },
      "source": [
        "# converting the textual data to numerical data\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(X)\n",
        "\n",
        "X = vectorizer.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = vectorizer.transform(test['content'].values)\n"
      ],
      "metadata": {
        "id": "HrQRYvwonxyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X1)"
      ],
      "metadata": {
        "id": "rEC-8o6yq953"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJj5esbs7Nzy"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKBRGiSQ7YCZ"
      },
      "source": [
        "Splitting the dataset to training & test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjMYwmBo7Pbx"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "Y_QnezznqaKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxDsQvgO8Oln"
      },
      "source": [
        "Training the Model: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrSItcqc7qAy"
      },
      "source": [
        "model = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdVJ839l8Vgx"
      },
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbPKIFT89W1C"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG6gqVty9ZDB"
      },
      "source": [
        "accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kgcn13oO-H6e"
      },
      "source": [
        "# accuracy score on the test data\n",
        "X_test_prediction = model.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(X_test_prediction, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TG0Yof1-vg2"
      },
      "source": [
        "print('Accuracy score of the test data : ', test_data_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBbWkLGr_lb_"
      },
      "source": [
        "test_prediction = model.predict(X1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame({\n",
        "    'id': test['id'],\n",
        "    'label': test_prediction\n",
        "})\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "tnm_ee8GnXpm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}